{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad8b0c2d",
   "metadata": {},
   "source": [
    "# Tokenisation\n",
    "\n",
    "**Pre-requisites:** Ratchet\n",
    "\n",
    "Tokenisation is the act of splitting up a continuous sequence into chunks, called tokens. A classic example is what the `split()` method does for strings. We will try to re-implement it.\n",
    "\n",
    "A description of the tokenisation algorithm is as follows:\n",
    "\n",
    "1. Iterate through each character of the string argument\n",
    "2. If the character does not match the delimiter, add it to an accumulator variable\n",
    "3. If the character matches the delimiter, add the accumulator variable to the return list and reset the accumulator variable\n",
    "\n",
    "### Exercise\n",
    "\n",
    "Write a function `split(text: str, delimiter: str) -> list` that splits up the string `text` at each occurrence of the character `delimiter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16718d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(text: str, delimiter: str) -> list:\n",
    "    \"\"\"Returns a list containing the result of splitting text at each occurrence of delimiter.\"\"\"\n",
    "    # Complete your code below.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378f0442",
   "metadata": {},
   "source": [
    "This pattern can be applied in many circumstances where the operation to be performed is conditional on each value in a sequence."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
